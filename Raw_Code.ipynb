{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable PyAutoGUI fail-safe (optional, use with caution)\n",
    "pyautogui.FAILSAFE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hands\n",
    "mp_Hands = mp.solutions.hands\n",
    "hand = mp_Hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_Drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get screen size for mapping hand coordinates to screen coordinates\n",
    "screen_width, screen_height = pyautogui.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing variables for cursor movement\n",
    "smoothing_factor = 0.1  # Lower value slows down cursor movement while keeping it smooth\n",
    "prev_x, prev_y = 0, 0   # Previous cursor position for smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click detection variables\n",
    "click_threshold = 0.07 # Distance threshold to detect finger bending\n",
    "click_duration_threshold = 0.7 # Seconds, if bend duration < this, it’s a click; else drag\n",
    "double_click_time = 1.0 # Seconds, time window to count multiple clicks\n",
    "action_delay = 0.35 # Seconds to wait after a bend ends before deciding action\n",
    "click_buffer = [] # List to store (start_time, end_time) of recent bends\n",
    "last_action_time = 0 # Time of last executed action\n",
    "is_dragging = False # Tracks drag state\n",
    "was_bent = False # Tracks index finger state\n",
    "bend_start_time = None # Tracks when the current bend started\n",
    "was_middle_bent = False # Tracks middle finger state for right click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom variables\n",
    "prev_thumb_index_distance = None\n",
    "zoom_threshold = 0.02\n",
    "last_zoom_time = 0\n",
    "zoom_debounce = 0.2\n",
    "zoom_active = False\n",
    "last_tap_time = 0\n",
    "tap_threshold = 0.08\n",
    "tap_debounce = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll variables\n",
    "scroll_active = False\n",
    "last_scroll_tap_time = 0\n",
    "last_scroll_time = 0\n",
    "scroll_delay = 0.05\n",
    "scroll_amount = 100\n",
    "upper_threshold = -0.05\n",
    "lower_threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand movement range for full screen coverage\n",
    "hand_range_x_min = 0.25\n",
    "hand_range_x_max = 0.75\n",
    "hand_range_y_min = 0.25\n",
    "hand_range_y_max = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand detection delay\n",
    "hand_detected_time = None\n",
    "gesture_delay = 2.0  # 2-second delay before gestures activate\n",
    "hand_present = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start webcam\n",
    "web_Cam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hand detected, waiting 2s to start gestures...\n",
      "Single left click\n",
      "Single left click\n",
      "Hand lost, resetting...\n",
      "Hand detected, waiting 2s to start gestures...\n",
      "Single left click\n",
      "Single left click\n",
      "Single left click\n",
      "Single left click\n",
      "Single left click\n",
      "Single left click\n",
      "Single left click\n",
      "Single left click\n",
      "Hand lost, resetting...\n",
      "Exiting program...\n"
     ]
    }
   ],
   "source": [
    "while web_Cam.isOpened():\n",
    "    succ, frame = web_Cam.read()\n",
    "    if not succ:\n",
    "        print(\"Failed to read from webcam.\")\n",
    "        break\n",
    "    \n",
    "    # Flip frame horizontally for a natural (mirror-like) experience\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    # Convert frame to RGB as MediaPipe expects RGB images\n",
    "    rgb_Frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process frame to detect hand landmarks\n",
    "    result = hand.process(rgb_Frame)\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Check if hand is present\n",
    "    if result.multi_hand_landmarks:\n",
    "        if not hand_present:\n",
    "            # Hand just appeared\n",
    "            hand_detected_time = current_time\n",
    "            hand_present = True\n",
    "            prev_thumb_index_distance = None  # Reset zoom baseline\n",
    "            print(\"Hand detected, waiting 2s to start gestures...\")\n",
    "    else:\n",
    "        if hand_present:\n",
    "            # Hand just disappeared\n",
    "            hand_present = False\n",
    "            hand_detected_time = None\n",
    "            prev_thumb_index_distance = None\n",
    "            zoom_active = False\n",
    "            scroll_active = False\n",
    "            is_dragging = False\n",
    "            click_buffer = []\n",
    "            print(\"Hand lost, resetting...\")\n",
    "\n",
    "    # Wait for gesture delay after hand detection\n",
    "    if hand_detected_time and current_time - hand_detected_time < gesture_delay:\n",
    "        cv2.putText(frame, \"Gestures start in {:.1f}s\".format(gesture_delay - (current_time - hand_detected_time)),\n",
    "                    (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    elif result.multi_hand_landmarks:\n",
    "        hand_landmarks = result.multi_hand_landmarks[0]\n",
    "\n",
    "        # Extract key landmarks\n",
    "        middle_mcp = hand_landmarks.landmark[mp_Hands.HandLandmark.MIDDLE_FINGER_MCP]\n",
    "        indx_tip = hand_landmarks.landmark[mp_Hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        indx_pip = hand_landmarks.landmark[mp_Hands.HandLandmark.INDEX_FINGER_PIP]\n",
    "        middle_tip = hand_landmarks.landmark[mp_Hands.HandLandmark.MIDDLE_FINGER_TIP]\n",
    "        middle_pip = hand_landmarks.landmark[mp_Hands.HandLandmark.MIDDLE_FINGER_PIP]\n",
    "        thumb_tip = hand_landmarks.landmark[mp_Hands.HandLandmark.THUMB_TIP]\n",
    "        thumb_mcp = hand_landmarks.landmark[mp_Hands.HandLandmark.THUMB_MCP]\n",
    "        ring_tip = hand_landmarks.landmark[mp_Hands.HandLandmark.RING_FINGER_TIP]\n",
    "        ring_pip = hand_landmarks.landmark[mp_Hands.HandLandmark.RING_FINGER_PIP]\n",
    "        # Get landmarks for pinky finger\n",
    "        pinky_tip = hand_landmarks.landmark[mp_Hands.HandLandmark.PINKY_TIP]\n",
    "        pinky_pip = hand_landmarks.landmark[mp_Hands.HandLandmark.PINKY_PIP]\n",
    "            \n",
    "\n",
    "        # Calculate distances between landmarks for gesture detection\n",
    "        tip_pip_distance = ((indx_tip.x - indx_pip.x) ** 2 + (indx_tip.y - indx_pip.y) ** 2) ** 0.5\n",
    "        middle_tip_pip_distance = ((middle_tip.x - middle_pip.x) ** 2 + (middle_tip.y - middle_pip.y) ** 2) ** 0.5\n",
    "        thumb_index_distance = ((thumb_tip.x - indx_tip.x) ** 2 + (thumb_tip.y - indx_tip.y) ** 2) ** 0.5\n",
    "        thumb_middle_distance = ((thumb_tip.x - middle_tip.x) ** 2 + (thumb_tip.y - middle_tip.y) ** 2) ** 0.5\n",
    "        ring_tip_pip_distance = ((ring_tip.x - ring_pip.x) ** 2 + (ring_tip.y - ring_pip.y) ** 2) ** 0.5\n",
    "        thumb_y_relative = thumb_tip.y - thumb_mcp.y\n",
    "\n",
    "        # Left button control\n",
    "        is_bent = tip_pip_distance < click_threshold\n",
    "        if is_bent and not was_bent:\n",
    "             # Finger just bent, start timing\n",
    "            bend_start_time = current_time\n",
    "        elif is_bent and bend_start_time is not None:\n",
    "            # Finger is bent, check duration\n",
    "            bend_duration = current_time - bend_start_time\n",
    "            if bend_duration >= click_duration_threshold and not is_dragging:\n",
    "                # Bend exceeds threshold, start dragging\n",
    "                pyautogui.mouseDown(button='left')\n",
    "                print(\"Drag started\")\n",
    "                is_dragging = True\n",
    "                click_buffer = [] # Clear buffer since it’s a drag\n",
    "        elif not is_bent and was_bent:\n",
    "            # Finger just extended\n",
    "            if is_dragging:\n",
    "                # End drag\n",
    "                pyautogui.mouseUp(button='left')\n",
    "                print(\"Drag ended\")\n",
    "                is_dragging = False\n",
    "            else:\n",
    "                # Short bend, potential click\n",
    "                if bend_start_time is not None:\n",
    "                    bend_duration = current_time - bend_start_time\n",
    "                    if bend_duration < click_duration_threshold:\n",
    "                        click_buffer.append((bend_start_time, current_time))\n",
    "            bend_start_time = None\n",
    "\n",
    "        # Process click buffer after delay\n",
    "        if click_buffer and current_time - click_buffer[-1][1] >= action_delay:\n",
    "            # Enough time has passed to process clicks\n",
    "            recent_clicks = [click for click in click_buffer if current_time - click[1] < double_click_time * 2]\n",
    "            if recent_clicks and current_time - last_action_time > action_delay:\n",
    "                click_count = len(recent_clicks)\n",
    "                if click_count >= 3 and recent_clicks[-1][1] - recent_clicks[-3][1] < double_click_time * 2:\n",
    "                    print(\"Triple left click\")\n",
    "                    pyautogui.click(clicks=3)\n",
    "                    last_action_time = current_time\n",
    "                elif click_count >= 2 and recent_clicks[-1][1] - recent_clicks[-2][1] < double_click_time:\n",
    "                    print(\"Double left click\")\n",
    "                    pyautogui.doubleClick()\n",
    "                    last_action_time = current_time\n",
    "                else:\n",
    "                    print(\"Single left click\")\n",
    "                    pyautogui.click()\n",
    "                    last_action_time = current_time\n",
    "            click_buffer = [] # Clear buffer after action\n",
    "\n",
    "        was_bent = is_bent\n",
    "\n",
    "        # Right button control\n",
    "        is_middle_bent = middle_tip_pip_distance < click_threshold\n",
    "        if is_middle_bent and not was_middle_bent:\n",
    "            pyautogui.click(button='right')\n",
    "            print(\"Performed right click\")\n",
    "        was_middle_bent = is_middle_bent\n",
    "\n",
    "        # Cursor movement (moves unless in scroll mode)\n",
    "        if not scroll_active:\n",
    "            x_normalized = (middle_mcp.x - hand_range_x_min) / (hand_range_x_max - hand_range_x_min)\n",
    "            y_normalized = (middle_mcp.y - hand_range_y_min) / (hand_range_y_max - hand_range_y_min)\n",
    "            x_normalized = max(0, min(1, x_normalized))\n",
    "            y_normalized = max(0, min(1, y_normalized))\n",
    "            x = int(x_normalized * screen_width)\n",
    "            y = int(y_normalized * screen_height)\n",
    "            x = int(smoothing_factor * x + (1 - smoothing_factor) * prev_x)\n",
    "            y = int(smoothing_factor * y + (1 - smoothing_factor) * prev_y)\n",
    "            prev_x, prev_y = x, y\n",
    "            pyautogui.moveTo(prev_x, prev_y)\n",
    "\n",
    "        # Check if pinky tip is below the pinky PIP joint\n",
    "        if pinky_tip.y > pinky_pip.y:  # Pinky tip lower than PIP means it's bent\n",
    "            zoom_active = not zoom_active  # Toggle zoom mode\n",
    "            print(\"Zoom Mode: ON\" if zoom_active else \"Zoom Mode: OFF\")  # Print status\n",
    "\n",
    "        # Scroll toggle (ring finger bent)\n",
    "        if ring_tip_pip_distance < click_threshold and current_time - last_scroll_tap_time > tap_debounce:\n",
    "            scroll_active = not scroll_active\n",
    "            last_scroll_tap_time = current_time\n",
    "            print(\"Scroll mode:\", \"ON\" if scroll_active else \"OFF\")\n",
    "\n",
    "        # Zoom functionality\n",
    "        if zoom_active and prev_thumb_index_distance is not None and current_time - last_zoom_time > zoom_debounce:\n",
    "            distance_change = thumb_index_distance - prev_thumb_index_distance\n",
    "            if abs(distance_change) > zoom_threshold:\n",
    "                if distance_change < 0:\n",
    "                    pyautogui.hotkey('ctrl', '+')\n",
    "                    print(\"Zoom in\")\n",
    "                    last_zoom_time = current_time\n",
    "                elif distance_change > 0:\n",
    "                    pyautogui.hotkey('ctrl', '-')\n",
    "                    print(\"Zoom out\")\n",
    "                    last_zoom_time = current_time\n",
    "        prev_thumb_index_distance = thumb_index_distance\n",
    "\n",
    "        # Scroll functionality\n",
    "        if scroll_active and current_time - last_scroll_time > scroll_delay:\n",
    "            if thumb_y_relative < upper_threshold:\n",
    "                pyautogui.scroll(scroll_amount)\n",
    "                print(\"Scroll up\")\n",
    "                last_scroll_time = current_time\n",
    "            elif thumb_y_relative > lower_threshold:\n",
    "                pyautogui.scroll(-scroll_amount)\n",
    "                print(\"Scroll down\")\n",
    "                last_scroll_time = current_time\n",
    "\n",
    "        # Draw hand landmarks\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            mp_Drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_Hands.HAND_CONNECTIONS,\n",
    "                mp_Drawing.DrawingSpec(color=(50, 50, 100), circle_radius=3, thickness=5)\n",
    "            )\n",
    "\n",
    "    # Display the frame and check for 'q' to exit\n",
    "    cv2.imshow(\"Hand Tracking\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        print(\"Exiting program...\")\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "web_Cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
